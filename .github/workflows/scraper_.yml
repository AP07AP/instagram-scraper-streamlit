name: Instagram Scraper

on:
  workflow_dispatch:
    inputs:
      profile_url:
        description: 'Instagram Profile URL'
        required: true
      start_date:
        description: 'Start Date (YYYY-MM-DD)'
        required: true
      end_date:
        description: 'End Date (YYYY-MM-DD)'
        required: true
      username:
        description: 'Instagram Username'
        required: true
      password:
        description: 'Instagram Password'
        required: true

jobs:
  scrape:
    runs-on: windows-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install pandas selenium

    - name: Run scraper
      run: |
        python scraper.py "${{ github.event.inputs.profile_url }}" \
                           "${{ github.event.inputs.start_date }}" \
                           "${{ github.event.inputs.end_date }}" \
                           "${{ github.event.inputs.username }}" \
                           "${{ github.event.inputs.password }}"

    - name: Upload scraped CSV as artifact
      run: |
        # Find the CSV dynamically
        set CSV_FILE=
        for %f in (*_${{ github.event.inputs.profile_url.strip('/').split('/')[-1] }}.csv) do set CSV_FILE=%f
        echo "CSV file found: %CSV_FILE%"
        echo "::set-output name=file::%CSV_FILE%"
      shell: cmd

    - name: Upload artifact
      uses: actions/upload-artifact@v4
      with:
        name: scraped_data
        path: ${{ steps.upload.outputs.file }}
